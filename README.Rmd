---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, echo = FALSE, message=FALSE, results='hide'}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.path = "man/figures/README-",
  echo = TRUE,
  fig.width = 8,
  fig.height = 6
)

```

<!-- badges: start -->
[![Project Status: WIP â€“ Initial development is in progress, but there has not yet been a stable, usable release suitable for the public.](https://www.repostatus.org/badges/latest/wip.svg)](https://www.repostatus.org/#wip)
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
[![CRAN status](https://www.r-pkg.org/badges/version/trending)](https://CRAN.R-project.org/package=trending)
[![Codecov test coverage](https://codecov.io/gh/reconhub/trending/branch/master/graph/badge.svg)](https://codecov.io/gh/reconhub/trending?branch=master)
[![R build status](https://github.com/reconhub/trending/workflows/R-CMD-check/badge.svg)](https://github.com/reconhub/trending/actions)
<!-- badges: end -->

<br>
**<span style="color: red;">Disclaimer</span>**

This package is a work in progress. Please reach out to the
authors before using.

# Trending

*trending* aims to provides a coherent interface to several modelling tools, 
alongside functions for model selection.  Whilst it is useful in an interactive 
context, it's main focus is to provide an intuitive interface on which other 
packages can be developed
(e.g. [*trendbreaker*](https://github.com/reconhub/trendbreaker)).

## Main features

- **Model specification:** Interfaces to common models through intuitive
  functions; `lm_model()`, `glm_model()`, `glm_nb_model`* and `brms_model`**.

- **Model fitting and prediction:** Once specified, models can be fit to data
  and generate prediction intervals for future data using `fit()` and 
  `predict()`.
  
- **Model evaluation and selection:** `evaluate_resampling()`, `evaluate_aic()`,
  `evaluate_models()` and `select_model()`.
  

\* &nbsp;Requires [MASS](https://CRAN.R-project.org/package=MASS)  
\*\* Requires [brms](https://CRAN.R-project.org/package=brms)
  

## Example usage

### An individual model 
```{r, warning=FALSE}
library(trendbreaker)  # for data
library(trending)      # for trends
library(dplyr, warn.conflicts = FALSE)  # for data manipulation

# load data
data(nhs_pathways_covid19)

# define a model
model = glm_nb_model(count ~ day + weekday)

# select last 6 weeks of data and group
first_date <- max(nhs_pathways_covid19$date, na.rm = TRUE) - 8*7
pathways_recent <- 
  nhs_pathways_covid19 %>% 
  filter(date >= first_date) %>% 
  group_by(date, day, weekday) %>% 
  summarise(count = sum(count), .groups = "drop")

# split data for fitting and prediction
dat <- 
  pathways_recent %>%
  group_by(date <= first_date + 6*7) %>% 
  group_split()

fitting_data <- dat[[2]]
pred_data <- select(dat[[1]], date, day , weekday)

fitted_model <- fit(model, fitting_data)

# prediction intervals
pred <- predict(fitted_model, pred_data)
glimpse(pred)
plot(pred, "date", fitted_data = fitting_data, fitted_y = "count")

# prediction intervals
conf <- confidence(fitted_model, pred_data)
glimpse(conf)
plot(conf, date_axis = "date", y = "pred",
     fitted_data = fitting_data, fitted_y = "count")

```

### Model selection

You can define a number of different regression models using a common interface.
Once defined you can use different strategies to select the
best-fitting/best-predicting model.

As an example we try to predict `hp` of the famous `mtcars` dataset.  Of course,
this is just a toy example. Usually you would use the package to predict counts
data in a time series.

First we define some potential models:
```{r}
stan_cache <- tempfile() # stan compile to c++ and we cache the code
models <- list(
  null = lm_model(hp ~ 1),
  glm_poisson = glm_model(hp ~ 1 + cyl + drat + wt + qsec + am, poisson),
  lm_complex = lm_model(hp ~ 1 + cyl + drat + wt + qsec + am),
  negbin_complex = glm_nb_model(hp ~ 1 + cyl + drat + wt + qsec + am),
  brms_complex = brms_model(
    hp ~ 1 + cyl + drat + wt + qsec + am,
    family = brms::negbinomial(),
    file = stan_cache
  )
)
```

Then we evaluate them using [N-Fold cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).

```{r, message=FALSE, warning=FALSE}
# we do CV and evaluate three loss function:
# Root-mean-squared error, the huber-loss and mean absolute error.
# The package works with `yardstick` by default.
out <- capture.output( # no log output in readme :)
  auto_select <- select_model(mtcars, models,
    method = evaluate_resampling,
    metrics = list(yardstick::rmse, yardstick::huber_loss, yardstick::mae)
  )
)
auto_select$leaderboard
```
